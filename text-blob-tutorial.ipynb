{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextBlob tutorial\n",
    "\n",
    "[Source](https://analyticsindiamag.com/lets-learn-textblob-quickstart-a-python-library-for-processing-textual-data/)\n",
    "\n",
    "**Textblob** is an open-source python library for processing textual data. It performs different operations on textual data such as noun phrase extraction, sentiment analysis, classification, translation, etc. \n",
    "\n",
    "Textblob is built on top of NLTK and Pattern also it is very easy to use and can process the text in a few lines of code. Textblob can help you start with the NLP tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\agarw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\agarw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\agarw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\agarw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download dependencies\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('brown')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text selection for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "art = '''Among the 10 countries that have reported the highest number of case in the world, daily cases are still continuously rising in only two – India and Colombia.  Other than the US and Brazil, daily cases also appear hitting a plateau in Mexico (7th spot, 480,278 cases). Russia (4th, 892,654 cases), South Africa (5th, 563,598 cases), and Chile (9th, 375,044 cases). The remaining two – Spain (10th, 370,060 cases) and Peru (7th, 483,133 cases) – managed to control outbreaks once, but are now seeing a resurgence of cases. All caseloads are from the worldometers.info dashboard. To be sure, the global Covid-19 curve has flattened twice before — first, when the Chinese outbreak peaked and the contagion was yet to reach the West; the second, when cases dropped in Europe — however, it has risen again with more ferocity both times as the virus has spread to new regions.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass text into TextBlob function\n",
    "blob = TextBlob(art)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Tags\n",
    "\n",
    "Tags function is used to find the respective tags of the particular word which describes whether the word is a noun, adjective, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Among', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('10', 'CD'),\n",
       " ('countries', 'NNS'),\n",
       " ('that', 'WDT'),\n",
       " ('have', 'VBP'),\n",
       " ('reported', 'VBN'),\n",
       " ('the', 'DT'),\n",
       " ('highest', 'JJS'),\n",
       " ('number', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('case', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('world', 'NN'),\n",
       " ('daily', 'JJ'),\n",
       " ('cases', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('still', 'RB'),\n",
       " ('continuously', 'RB'),\n",
       " ('rising', 'VBG'),\n",
       " ('in', 'IN'),\n",
       " ('only', 'JJ'),\n",
       " ('two', 'CD'),\n",
       " ('–', 'JJ'),\n",
       " ('India', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Colombia', 'NNP'),\n",
       " ('Other', 'JJ'),\n",
       " ('than', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('US', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Brazil', 'NNP'),\n",
       " ('daily', 'JJ'),\n",
       " ('cases', 'NNS'),\n",
       " ('also', 'RB'),\n",
       " ('appear', 'VBP'),\n",
       " ('hitting', 'VBG'),\n",
       " ('a', 'DT'),\n",
       " ('plateau', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('Mexico', 'NNP'),\n",
       " ('7th', 'CD'),\n",
       " ('spot', 'NN'),\n",
       " ('480,278', 'CD'),\n",
       " ('cases', 'NNS'),\n",
       " ('Russia', 'NNP'),\n",
       " ('4th', 'CD'),\n",
       " ('892,654', 'CD'),\n",
       " ('cases', 'NNS'),\n",
       " ('South', 'NNP'),\n",
       " ('Africa', 'NNP'),\n",
       " ('5th', 'CD'),\n",
       " ('563,598', 'CD'),\n",
       " ('cases', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('Chile', 'NNP'),\n",
       " ('9th', 'CD'),\n",
       " ('375,044', 'CD'),\n",
       " ('cases', 'NNS'),\n",
       " ('The', 'DT'),\n",
       " ('remaining', 'VBG'),\n",
       " ('two', 'CD'),\n",
       " ('–', 'JJ'),\n",
       " ('Spain', 'NNP'),\n",
       " ('10th', 'CD'),\n",
       " ('370,060', 'CD'),\n",
       " ('cases', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('Peru', 'NNP'),\n",
       " ('7th', 'CD'),\n",
       " ('483,133', 'CD'),\n",
       " ('cases', 'NNS'),\n",
       " ('–', 'VBP'),\n",
       " ('managed', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('control', 'VB'),\n",
       " ('outbreaks', 'JJ'),\n",
       " ('once', 'RB'),\n",
       " ('but', 'CC'),\n",
       " ('are', 'VBP'),\n",
       " ('now', 'RB'),\n",
       " ('seeing', 'VBG'),\n",
       " ('a', 'DT'),\n",
       " ('resurgence', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('cases', 'NNS'),\n",
       " ('All', 'DT'),\n",
       " ('caseloads', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('from', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('worldometers.info', 'JJ'),\n",
       " ('dashboard', 'NN'),\n",
       " ('To', 'TO'),\n",
       " ('be', 'VB'),\n",
       " ('sure', 'JJ'),\n",
       " ('the', 'DT'),\n",
       " ('global', 'JJ'),\n",
       " ('Covid-19', 'NNP'),\n",
       " ('curve', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('flattened', 'VBN'),\n",
       " ('twice', 'RB'),\n",
       " ('before', 'RB'),\n",
       " ('—', 'JJ'),\n",
       " ('first', 'RB'),\n",
       " ('when', 'WRB'),\n",
       " ('the', 'DT'),\n",
       " ('Chinese', 'JJ'),\n",
       " ('outbreak', 'NN'),\n",
       " ('peaked', 'VBD'),\n",
       " ('and', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('contagion', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('yet', 'RB'),\n",
       " ('to', 'TO'),\n",
       " ('reach', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('West', 'NNP'),\n",
       " ('the', 'DT'),\n",
       " ('second', 'JJ'),\n",
       " ('when', 'WRB'),\n",
       " ('cases', 'NNS'),\n",
       " ('dropped', 'VBD'),\n",
       " ('in', 'IN'),\n",
       " ('Europe', 'NNP'),\n",
       " ('—', 'NNP'),\n",
       " ('however', 'RB'),\n",
       " ('it', 'PRP'),\n",
       " ('has', 'VBZ'),\n",
       " ('risen', 'VBN'),\n",
       " ('again', 'RB'),\n",
       " ('with', 'IN'),\n",
       " ('more', 'JJR'),\n",
       " ('ferocity', 'NN'),\n",
       " ('both', 'DT'),\n",
       " ('times', 'NNS'),\n",
       " ('as', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('virus', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('spread', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('new', 'JJ'),\n",
       " ('regions', 'NNS')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find tags\n",
    "blob.tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noun Phrases\n",
    "\n",
    "Noun phrases function helps us find out the noun phrases in the text given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['india', 'colombia', 'brazil', 'mexico', '7th spot', 'russia', 'africa', 'chile', 'spain', 'peru', 'worldometers.info dashboard', 'covid-19', 'chinese outbreak', 'europe', 'new regions'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.noun_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiments\n",
    "\n",
    "Sentiment function is used to find out the polarity and subjectivity of the text. The polarity is used to check whether the text is positive or negative and subjectivity is used to check whether the text is objective or subjective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.1146694214876033, subjectivity=0.3228879706152434)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words\n",
    "\n",
    "Words function split the text into words that are used in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Among', 'the', '10', 'countries', 'that', 'have', 'reported', 'the', 'highest', 'number', 'of', 'case', 'in', 'the', 'world', 'daily', 'cases', 'are', 'still', 'continuously', 'rising', 'in', 'only', 'two', '–', 'India', 'and', 'Colombia', 'Other', 'than', 'the', 'US', 'and', 'Brazil', 'daily', 'cases', 'also', 'appear', 'hitting', 'a', 'plateau', 'in', 'Mexico', '7th', 'spot', '480,278', 'cases', 'Russia', '4th', '892,654', 'cases', 'South', 'Africa', '5th', '563,598', 'cases', 'and', 'Chile', '9th', '375,044', 'cases', 'The', 'remaining', 'two', '–', 'Spain', '10th', '370,060', 'cases', 'and', 'Peru', '7th', '483,133', 'cases', '–', 'managed', 'to', 'control', 'outbreaks', 'once', 'but', 'are', 'now', 'seeing', 'a', 'resurgence', 'of', 'cases', 'All', 'caseloads', 'are', 'from', 'the', 'worldometers.info', 'dashboard', 'To', 'be', 'sure', 'the', 'global', 'Covid-19', 'curve', 'has', 'flattened', 'twice', 'before', '—', 'first', 'when', 'the', 'Chinese', 'outbreak', 'peaked', 'and', 'the', 'contagion', 'was', 'yet', 'to', 'reach', 'the', 'West', 'the', 'second', 'when', 'cases', 'dropped', 'in', 'Europe', '—', 'however', 'it', 'has', 'risen', 'again', 'with', 'more', 'ferocity', 'both', 'times', 'as', 'the', 'virus', 'has', 'spread', 'to', 'new', 'regions'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentences\n",
    "\n",
    "Sentences function split the text into the sentences which are used to form the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"Among the 10 countries that have reported the highest number of case in the world, daily cases are still continuously rising in only two – India and Colombia.\"),\n",
       " Sentence(\"Other than the US and Brazil, daily cases also appear hitting a plateau in Mexico (7th spot, 480,278 cases).\"),\n",
       " Sentence(\"Russia (4th, 892,654 cases), South Africa (5th, 563,598 cases), and Chile (9th, 375,044 cases).\"),\n",
       " Sentence(\"The remaining two – Spain (10th, 370,060 cases) and Peru (7th, 483,133 cases) – managed to control outbreaks once, but are now seeing a resurgence of cases.\"),\n",
       " Sentence(\"All caseloads are from the worldometers.info dashboard.\"),\n",
       " Sentence(\"To be sure, the global Covid-19 curve has flattened twice before — first, when the Chinese outbreak peaked and the contagion was yet to reach the West; the second, when cases dropped in Europe — however, it has risen again with more ferocity both times as the virus has spread to new regions.\")]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also find the polarity of all individual sentences using the polarity function mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "-0.0625\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.19805194805194803\n"
     ]
    }
   ],
   "source": [
    "for sentence in blob.sentences:\n",
    "    print(sentence.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singularize and Pluralize\n",
    "\n",
    "We can select different words from our text and can singularize and pluralize them. Similarly, we can pass any word and convert it into a singular or plural form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_text = blob.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('countries', 'that')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_text[3], word_text[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'country'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_text[3].singularize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'those'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_text[4].pluralize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatize\n",
    "\n",
    "Lemmatize function is used to find out the lemma for the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Among', 'the', '10', 'countries', 'that', 'have', 'reported', 'the', 'highest', 'number']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WordList(['Among', 'the', '10', 'country', 'that', 'have', 'reported', 'the', 'highest', 'number'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(word_text[:10])\n",
    "word_text[:10].lemmatize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spell check and correct\n",
    "\n",
    "Spell check function and correct function helps in checking and correcting the spelling mistakes in our sentence or word or article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = TextBlob(\"Amnog the 10 countrees that have reporded the highest number  of case in the world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Among the 10 countries that have reported the highest number  of case in the world\")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('among', 0.9933920704845814),\n",
       " ('amoy', 0.0022026431718061676),\n",
       " ('amos', 0.0022026431718061676),\n",
       " ('agog', 0.0022026431718061676)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = Word('amog')\n",
    "\n",
    "w.spellcheck()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing text\n",
    "\n",
    "By default, Textblob uses Pattern’s parser. We will parse our text using the parser function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Among/IN/B-PP/B-PNP the/DT/B-NP/I-PNP 10/CD/I-NP/I-PNP countries/NNS/I-NP/I-PNP that/IN/B-PP/O have/VBP/B-VP/O reported/VBD/I-VP/O the/DT/B-NP/O highest/JJS/I-NP/O number/NN/I-NP/O of/IN/B-PP/B-PNP case/NN/B-NP/I-PNP in/IN/B-PP/B-PNP the/DT/B-NP/I-PNP world/NN/I-NP/I-PNP ,/,/O/O daily/JJ/B-NP/O cases/NNS/I-NP/O are/VBP/B-VP/O still/RB/I-VP/O continuously/RB/I-VP/O rising/VBG/I-VP/O in/IN/B-PP/O only/RB/B-ADVP/O two/CD/O/O –/,/O/O India/NNP/B-NP/O and/CC/I-NP/O Colombia/NNP/I-NP/O ././O/O\\nOther/JJ/B-ADJP/O than/IN/B-PP/B-PNP the/DT/B-NP/I-PNP US/PRP/I-NP/I-PNP and/CC/O/O Brazil/NNP/B-NP/O ,/,/O/O daily/JJ/B-NP/O cases/NNS/I-NP/O also/RB/B-VP/O appear/VB/I-VP/O hitting/VBG/I-VP/O a/DT/B-NP/O plateau/NN/I-NP/O in/IN/B-PP/B-PNP Mexico/NNP/B-NP/I-PNP (/(/O/O 7th/NN/B-NP/O spot/NN/I-NP/O ,/,/O/O 480,278/CD/B-NP/O cases/NNS/I-NP/O )/)/O/O ././O/O\\nRussia/NNP/B-NP/O (/(/O/O 4th/CD/O/O ,/,/O/O 892,654/CD/B-NP/O cases/NNS/I-NP/O )/)/O/O ,/,/O/O South/NNP/B-NP/O Africa/NNP/I-NP/O (/(/O/O 5th/NN/B-NP/O ,/,/O/O 563,598/CD/B-NP/O cases/NNS/I-NP/O )/)/O/O ,/,/O/O and/CC/O/O Chile/NNP/B-NP/O (/(/O/O 9th/NN/B-NP/O ,/,/O/O 375,044/CD/B-NP/O cases/NNS/I-NP/O )/)/O/O ././O/O\\nThe/DT/O/O remaining/VBG/B-VP/O two/CD/O/O –/,/O/O Spain/NNP/B-NP/O (/(/O/O 10th/NN/B-NP/O ,/,/O/O 370,060/CD/B-NP/O cases/NNS/I-NP/O )/)/O/O and/CC/O/O Peru/NNP/B-NP/O (/(/O/O 7th/NN/B-NP/O ,/,/O/O 483,133/CD/B-NP/O cases/NNS/I-NP/O )/)/O/O –/,/O/O managed/VBD/B-VP/O to/TO/B-PP/B-PNP control/NN/B-NP/I-PNP outbreaks/NNS/I-NP/I-PNP once/RB/B-ADVP/O ,/,/O/O but/CC/O/O are/VBP/B-VP/O now/RB/I-VP/O seeing/VBG/I-VP/O a/DT/B-NP/O resurgence/NN/I-NP/O of/IN/B-PP/B-PNP cases/NNS/B-NP/I-PNP ././O/O\\nAll/DT/B-NP/O caseloads/NNS/I-NP/O are/VBP/B-VP/O from/IN/B-PP/B-PNP the/DT/B-NP/I-PNP worldometers.info/NN/I-NP/I-PNP dashboard/NN/I-NP/I-PNP ././O/O\\nTo/TO/B-PP/O be/VB/B-VP/O sure/JJ/B-ADJP/O ,/,/O/O the/DT/B-NP/O global/JJ/I-NP/O Covid-19/NNP/I-NP/O curve/NN/I-NP/O has/VBZ/B-VP/O flattened/VBN/I-VP/O twice/RB/B-ADVP/O before/IN/B-PP/B-PNP —/NN/B-NP/I-PNP first/JJ/B-ADJP/O ,/,/O/O when/WRB/B-ADVP/O the/DT/B-NP/O Chinese/JJ/I-NP/O outbreak/NN/I-NP/O peaked/VBD/B-VP/O and/CC/O/O the/DT/B-NP/O contagion/NN/I-NP/O was/VBD/B-VP/O yet/RB/B-ADVP/O to/TO/B-PP/O reach/VB/B-VP/O the/DT/B-NP/O West/NNP/I-NP/O ;/:/O/O the/DT/O/O second/JJ/B-ADJP/O ,/,/O/O when/WRB/B-ADVP/O cases/NNS/B-NP/O dropped/VBD/B-VP/O in/IN/B-PP/B-PNP Europe/NNP/B-NP/I-PNP —/NN/I-NP/I-PNP however/RB/B-ADVP/O ,/,/O/O it/PRP/B-NP/O has/VBZ/B-VP/O risen/VBN/I-VP/O again/RB/B-ADVP/O with/IN/B-PP/B-PNP more/JJR/B-NP/I-PNP ferocity/NN/I-NP/I-PNP both/DT/B-NP/I-PNP times/NNS/I-NP/I-PNP as/IN/B-PP/B-PNP the/DT/B-NP/I-PNP virus/NN/I-NP/I-PNP has/VBZ/B-VP/O spread/NN/B-NP/O to/TO/B-PP/B-PNP new/JJ/B-NP/I-PNP regions/NNS/I-NP/I-PNP ././O/O'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.parse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Grams\n",
    "\n",
    "N-grams function returns a tuple of n successive words from a given text. You just need to pass the value of n in the n-gram function to decide the number of words in the n-gram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['Among', 'the', '10', 'countries', 'that']),\n",
       " WordList(['the', '10', 'countries', 'that', 'have']),\n",
       " WordList(['10', 'countries', 'that', 'have', 'reported']),\n",
       " WordList(['countries', 'that', 'have', 'reported', 'the']),\n",
       " WordList(['that', 'have', 'reported', 'the', 'highest']),\n",
       " WordList(['have', 'reported', 'the', 'highest', 'number']),\n",
       " WordList(['reported', 'the', 'highest', 'number', 'of']),\n",
       " WordList(['the', 'highest', 'number', 'of', 'case']),\n",
       " WordList(['highest', 'number', 'of', 'case', 'in']),\n",
       " WordList(['number', 'of', 'case', 'in', 'the']),\n",
       " WordList(['of', 'case', 'in', 'the', 'world']),\n",
       " WordList(['case', 'in', 'the', 'world', 'daily']),\n",
       " WordList(['in', 'the', 'world', 'daily', 'cases']),\n",
       " WordList(['the', 'world', 'daily', 'cases', 'are']),\n",
       " WordList(['world', 'daily', 'cases', 'are', 'still']),\n",
       " WordList(['daily', 'cases', 'are', 'still', 'continuously']),\n",
       " WordList(['cases', 'are', 'still', 'continuously', 'rising']),\n",
       " WordList(['are', 'still', 'continuously', 'rising', 'in']),\n",
       " WordList(['still', 'continuously', 'rising', 'in', 'only']),\n",
       " WordList(['continuously', 'rising', 'in', 'only', 'two']),\n",
       " WordList(['rising', 'in', 'only', 'two', '–']),\n",
       " WordList(['in', 'only', 'two', '–', 'India']),\n",
       " WordList(['only', 'two', '–', 'India', 'and']),\n",
       " WordList(['two', '–', 'India', 'and', 'Colombia']),\n",
       " WordList(['–', 'India', 'and', 'Colombia', 'Other']),\n",
       " WordList(['India', 'and', 'Colombia', 'Other', 'than']),\n",
       " WordList(['and', 'Colombia', 'Other', 'than', 'the']),\n",
       " WordList(['Colombia', 'Other', 'than', 'the', 'US']),\n",
       " WordList(['Other', 'than', 'the', 'US', 'and']),\n",
       " WordList(['than', 'the', 'US', 'and', 'Brazil']),\n",
       " WordList(['the', 'US', 'and', 'Brazil', 'daily']),\n",
       " WordList(['US', 'and', 'Brazil', 'daily', 'cases']),\n",
       " WordList(['and', 'Brazil', 'daily', 'cases', 'also']),\n",
       " WordList(['Brazil', 'daily', 'cases', 'also', 'appear']),\n",
       " WordList(['daily', 'cases', 'also', 'appear', 'hitting']),\n",
       " WordList(['cases', 'also', 'appear', 'hitting', 'a']),\n",
       " WordList(['also', 'appear', 'hitting', 'a', 'plateau']),\n",
       " WordList(['appear', 'hitting', 'a', 'plateau', 'in']),\n",
       " WordList(['hitting', 'a', 'plateau', 'in', 'Mexico']),\n",
       " WordList(['a', 'plateau', 'in', 'Mexico', '7th']),\n",
       " WordList(['plateau', 'in', 'Mexico', '7th', 'spot']),\n",
       " WordList(['in', 'Mexico', '7th', 'spot', '480,278']),\n",
       " WordList(['Mexico', '7th', 'spot', '480,278', 'cases']),\n",
       " WordList(['7th', 'spot', '480,278', 'cases', 'Russia']),\n",
       " WordList(['spot', '480,278', 'cases', 'Russia', '4th']),\n",
       " WordList(['480,278', 'cases', 'Russia', '4th', '892,654']),\n",
       " WordList(['cases', 'Russia', '4th', '892,654', 'cases']),\n",
       " WordList(['Russia', '4th', '892,654', 'cases', 'South']),\n",
       " WordList(['4th', '892,654', 'cases', 'South', 'Africa']),\n",
       " WordList(['892,654', 'cases', 'South', 'Africa', '5th']),\n",
       " WordList(['cases', 'South', 'Africa', '5th', '563,598']),\n",
       " WordList(['South', 'Africa', '5th', '563,598', 'cases']),\n",
       " WordList(['Africa', '5th', '563,598', 'cases', 'and']),\n",
       " WordList(['5th', '563,598', 'cases', 'and', 'Chile']),\n",
       " WordList(['563,598', 'cases', 'and', 'Chile', '9th']),\n",
       " WordList(['cases', 'and', 'Chile', '9th', '375,044']),\n",
       " WordList(['and', 'Chile', '9th', '375,044', 'cases']),\n",
       " WordList(['Chile', '9th', '375,044', 'cases', 'The']),\n",
       " WordList(['9th', '375,044', 'cases', 'The', 'remaining']),\n",
       " WordList(['375,044', 'cases', 'The', 'remaining', 'two']),\n",
       " WordList(['cases', 'The', 'remaining', 'two', '–']),\n",
       " WordList(['The', 'remaining', 'two', '–', 'Spain']),\n",
       " WordList(['remaining', 'two', '–', 'Spain', '10th']),\n",
       " WordList(['two', '–', 'Spain', '10th', '370,060']),\n",
       " WordList(['–', 'Spain', '10th', '370,060', 'cases']),\n",
       " WordList(['Spain', '10th', '370,060', 'cases', 'and']),\n",
       " WordList(['10th', '370,060', 'cases', 'and', 'Peru']),\n",
       " WordList(['370,060', 'cases', 'and', 'Peru', '7th']),\n",
       " WordList(['cases', 'and', 'Peru', '7th', '483,133']),\n",
       " WordList(['and', 'Peru', '7th', '483,133', 'cases']),\n",
       " WordList(['Peru', '7th', '483,133', 'cases', '–']),\n",
       " WordList(['7th', '483,133', 'cases', '–', 'managed']),\n",
       " WordList(['483,133', 'cases', '–', 'managed', 'to']),\n",
       " WordList(['cases', '–', 'managed', 'to', 'control']),\n",
       " WordList(['–', 'managed', 'to', 'control', 'outbreaks']),\n",
       " WordList(['managed', 'to', 'control', 'outbreaks', 'once']),\n",
       " WordList(['to', 'control', 'outbreaks', 'once', 'but']),\n",
       " WordList(['control', 'outbreaks', 'once', 'but', 'are']),\n",
       " WordList(['outbreaks', 'once', 'but', 'are', 'now']),\n",
       " WordList(['once', 'but', 'are', 'now', 'seeing']),\n",
       " WordList(['but', 'are', 'now', 'seeing', 'a']),\n",
       " WordList(['are', 'now', 'seeing', 'a', 'resurgence']),\n",
       " WordList(['now', 'seeing', 'a', 'resurgence', 'of']),\n",
       " WordList(['seeing', 'a', 'resurgence', 'of', 'cases']),\n",
       " WordList(['a', 'resurgence', 'of', 'cases', 'All']),\n",
       " WordList(['resurgence', 'of', 'cases', 'All', 'caseloads']),\n",
       " WordList(['of', 'cases', 'All', 'caseloads', 'are']),\n",
       " WordList(['cases', 'All', 'caseloads', 'are', 'from']),\n",
       " WordList(['All', 'caseloads', 'are', 'from', 'the']),\n",
       " WordList(['caseloads', 'are', 'from', 'the', 'worldometers.info']),\n",
       " WordList(['are', 'from', 'the', 'worldometers.info', 'dashboard']),\n",
       " WordList(['from', 'the', 'worldometers.info', 'dashboard', 'To']),\n",
       " WordList(['the', 'worldometers.info', 'dashboard', 'To', 'be']),\n",
       " WordList(['worldometers.info', 'dashboard', 'To', 'be', 'sure']),\n",
       " WordList(['dashboard', 'To', 'be', 'sure', 'the']),\n",
       " WordList(['To', 'be', 'sure', 'the', 'global']),\n",
       " WordList(['be', 'sure', 'the', 'global', 'Covid-19']),\n",
       " WordList(['sure', 'the', 'global', 'Covid-19', 'curve']),\n",
       " WordList(['the', 'global', 'Covid-19', 'curve', 'has']),\n",
       " WordList(['global', 'Covid-19', 'curve', 'has', 'flattened']),\n",
       " WordList(['Covid-19', 'curve', 'has', 'flattened', 'twice']),\n",
       " WordList(['curve', 'has', 'flattened', 'twice', 'before']),\n",
       " WordList(['has', 'flattened', 'twice', 'before', '—']),\n",
       " WordList(['flattened', 'twice', 'before', '—', 'first']),\n",
       " WordList(['twice', 'before', '—', 'first', 'when']),\n",
       " WordList(['before', '—', 'first', 'when', 'the']),\n",
       " WordList(['—', 'first', 'when', 'the', 'Chinese']),\n",
       " WordList(['first', 'when', 'the', 'Chinese', 'outbreak']),\n",
       " WordList(['when', 'the', 'Chinese', 'outbreak', 'peaked']),\n",
       " WordList(['the', 'Chinese', 'outbreak', 'peaked', 'and']),\n",
       " WordList(['Chinese', 'outbreak', 'peaked', 'and', 'the']),\n",
       " WordList(['outbreak', 'peaked', 'and', 'the', 'contagion']),\n",
       " WordList(['peaked', 'and', 'the', 'contagion', 'was']),\n",
       " WordList(['and', 'the', 'contagion', 'was', 'yet']),\n",
       " WordList(['the', 'contagion', 'was', 'yet', 'to']),\n",
       " WordList(['contagion', 'was', 'yet', 'to', 'reach']),\n",
       " WordList(['was', 'yet', 'to', 'reach', 'the']),\n",
       " WordList(['yet', 'to', 'reach', 'the', 'West']),\n",
       " WordList(['to', 'reach', 'the', 'West', 'the']),\n",
       " WordList(['reach', 'the', 'West', 'the', 'second']),\n",
       " WordList(['the', 'West', 'the', 'second', 'when']),\n",
       " WordList(['West', 'the', 'second', 'when', 'cases']),\n",
       " WordList(['the', 'second', 'when', 'cases', 'dropped']),\n",
       " WordList(['second', 'when', 'cases', 'dropped', 'in']),\n",
       " WordList(['when', 'cases', 'dropped', 'in', 'Europe']),\n",
       " WordList(['cases', 'dropped', 'in', 'Europe', '—']),\n",
       " WordList(['dropped', 'in', 'Europe', '—', 'however']),\n",
       " WordList(['in', 'Europe', '—', 'however', 'it']),\n",
       " WordList(['Europe', '—', 'however', 'it', 'has']),\n",
       " WordList(['—', 'however', 'it', 'has', 'risen']),\n",
       " WordList(['however', 'it', 'has', 'risen', 'again']),\n",
       " WordList(['it', 'has', 'risen', 'again', 'with']),\n",
       " WordList(['has', 'risen', 'again', 'with', 'more']),\n",
       " WordList(['risen', 'again', 'with', 'more', 'ferocity']),\n",
       " WordList(['again', 'with', 'more', 'ferocity', 'both']),\n",
       " WordList(['with', 'more', 'ferocity', 'both', 'times']),\n",
       " WordList(['more', 'ferocity', 'both', 'times', 'as']),\n",
       " WordList(['ferocity', 'both', 'times', 'as', 'the']),\n",
       " WordList(['both', 'times', 'as', 'the', 'virus']),\n",
       " WordList(['times', 'as', 'the', 'virus', 'has']),\n",
       " WordList(['as', 'the', 'virus', 'has', 'spread']),\n",
       " WordList(['the', 'virus', 'has', 'spread', 'to']),\n",
       " WordList(['virus', 'has', 'spread', 'to', 'new']),\n",
       " WordList(['has', 'spread', 'to', 'new', 'regions'])]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.ngrams(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are some of the text processing functions that are provided by textblob. We can use textblob for text processing as it is easy to use and has a lot of predefined functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
